{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from matplotlib) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: torch in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from torch) (75.8.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: tqdm in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (4.67.1)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from scikit-learn) (2.2.3)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.15.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.6.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n",
      "Using cached scipy-1.15.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0\n",
      "Requirement already satisfied: nltk in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: tensorboard in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from tensorboard) (2.2.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from tensorboard) (1.71.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from tensorboard) (2.2.3)\n",
      "Requirement already satisfied: packaging in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from tensorboard) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from tensorboard) (6.30.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from tensorboard) (75.8.1)\n",
      "Requirement already satisfied: six>1.9 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from tensorboard) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ikulkar1/miniconda3/envs/203A3E1/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torchsummaryy (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torchsummaryy\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "!pip install torch\n",
    "!pip install tqdm\n",
    "!pip install scikit-learn\n",
    "!pip install nltk\n",
    "!pip install tensorboard\n",
    "!pip install torchsummaryy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from conlleval import evaluate as conllevaluate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax(vec):\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n",
    "\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix.get(w, to_ix['<UNK>']) for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + \\\n",
    "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
    "\n",
    "\n",
    "# Hamming distance calculation\n",
    "def hamming_distance(y_pred, y_gold):\n",
    "    \"\"\"Calculate hamming distance between predicted and gold sequences\"\"\"\n",
    "    return sum(y1 != y2 for y1, y2 in zip(y_pred, y_gold))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Train size: 14987, Dev size: 3466, Test size: 3684\n",
      "Vocabulary size: 30293, Tag set size: 10\n"
     ]
    }
   ],
   "source": [
    "class BiLSTM_CRF(nn.Module): \n",
    "\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim, char_embedding_dim):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "\n",
    "        self.transitions = nn.Parameter(\n",
    "            torch.randn(self.tagset_size, self.tagset_size))\n",
    "\n",
    "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "        self.hidden = self.init_hidden()\n",
    "        self.char_embed = nn.Embedding(10, char_embedding_dim)\n",
    "        self.char_cnn = nn.Conv2d(in_channels=1, out_channels=char_embedding_dim, kernel_size=(1, char_embedding_dim))\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(2, 1, self.hidden_dim // 2),\n",
    "                torch.randn(2, 1, self.hidden_dim // 2))\n",
    "\n",
    "    def _forward_alg(self, feats):\n",
    "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
    "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
    "\n",
    "        forward_var = init_alphas\n",
    "        device_info = forward_var.device \n",
    "        for feat in feats:\n",
    "            alphas_t = []  \n",
    "            for next_tag in range(self.tagset_size):\n",
    "                emit_score = feat[next_tag].view(\n",
    "                    1, -1).expand(1, self.tagset_size).to(device_info)\n",
    "                trans_score = self.transitions[next_tag].view(1, -1).to(device_info)\n",
    "                next_tag_var = forward_var + trans_score + emit_score\n",
    "         \n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]].to(device_info)\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        return alpha\n",
    "\n",
    "    def _get_lstm_features(self, sentence): \n",
    "        self.hidden = self.init_hidden()\n",
    "        sentence = sentence.to(self.word_embeds.weight.device)\n",
    "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
    "        self.hidden = tuple(h.to(embeds.device) for h in self.hidden)\n",
    "        lstm_out, self.hidden = self.lstm(embeds, self.hidden) \n",
    "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "        return lstm_feats\n",
    "\n",
    "    def get_char_indices(self, word_idx):\n",
    "        \"\"\"\n",
    "        Extracts character indices using nltk.word_tokenize.\n",
    "        \"\"\"\n",
    "        char_idx = [word_to_idx[char] for char in train_data[word_idx]['tokens']] \n",
    "        return char_idx\n",
    "\n",
    "    def _get_lstm_features_cnn(self, sentence):\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "        sentence = sentence.to(self.word_embeds.weight.device)\n",
    "        char_embeddings, char_ids = self.char_embed, []\n",
    "        for word_idx in sentence:\n",
    "           \n",
    "            chars = self.get_char_indices(word_idx) \n",
    "            char_ids.append(torch.tensor(chars).to(device))\n",
    "                            \n",
    "        char_ids = pad_sequence(char_ids, batch_first=True, padding_value=0) \n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=char_embeddings.num_embeddings,  out_channels=11,  kernel_size=3, padding=1)  \n",
    "        cnn_out = self.conv1(char_embeddings(char_ids))\n",
    "        lstm_out = torch.max(F.relu(cnn_out), dim=2)[0] \n",
    "        lstm_out = lstm_out.view(len(sentence), -1)\n",
    "        lstm_out, self.hidden = self.lstm(lstm_out, self.hidden)\n",
    "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim * 2)\n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "\n",
    "        return lstm_feats\n",
    "\n",
    "    def _score_sentence(self, feats, tags):\n",
    "        score = torch.zeros(1, device=feats.device)\n",
    "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long, device=feats.device), tags])\n",
    "        for i, feat in enumerate(feats):\n",
    "            score = score + \\\n",
    "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "\n",
    "    def _viterbi_decode(self, feats, gold_tags=None, cost_scale=0):\n",
    "        \"\"\"\n",
    "        Run Viterbi algorithm to get the best tag sequence.\n",
    "        With cost_scale > 0, it performs cost-augmented inference.\n",
    "        \"\"\"\n",
    "        backpointers = []\n",
    "\n",
    "        init_vvars = torch.full((1, self.tagset_size), -10000., device=feats.device)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "\n",
    "        forward_var = init_vvars\n",
    "        for i, feat in enumerate(feats):\n",
    "            bptrs_t = [] \n",
    "            viterbivars_t = []  \n",
    "\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                \n",
    "                # Cost-augmented decoding: add cost when gold and predicted tags differ\n",
    "                if cost_scale > 0 and gold_tags is not None and i < len(gold_tags):\n",
    "                    cost = torch.zeros(self.tagset_size, device=feats.device)\n",
    "                    cost[gold_tags[i]] = 0  # No cost for correct tag\n",
    "                    # 10x cost (hamming distance) for incorrect tags\n",
    "                    mask = torch.ones(self.tagset_size, device=feats.device)\n",
    "                    mask[gold_tags[i]] = 0\n",
    "                    cost = cost_scale * mask  # Apply cost to incorrect tags\n",
    "                    next_tag_var = next_tag_var + cost\n",
    "                \n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            \n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        best_tag_id = argmax(terminal_var)\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag_to_ix[START_TAG]\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def neg_log_likelihood(self, sentence, tags):\n",
    "        \"\"\"Standard negative log likelihood loss for CRF\"\"\"\n",
    "        feats = self._get_lstm_features(sentence)\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    def structured_svm_loss(self, sentence, tags, cost_scale=10.0):\n",
    "        \"\"\"\n",
    "        Structured SVM loss with cost-augmented decoding.\n",
    "        L(x,y,w) = max_{y'} [score(x,y',w) + cost(y,y')] - score(x,y,w)\n",
    "        \"\"\"\n",
    "        feats = self._get_lstm_features(sentence)\n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "        \n",
    "        # Cost-augmented decoding\n",
    "        cost_augmented_score, predicted_tags = self._viterbi_decode(feats, tags, cost_scale)\n",
    "        \n",
    "        # Margin-based loss: max(0, cost_augmented_score - gold_score + hamming_distance*cost_scale)\n",
    "        margin = cost_augmented_score - gold_score\n",
    "        \n",
    "        return margin if margin > 0 else torch.zeros_like(margin)\n",
    "\n",
    "    def forward(self, sentence):  \n",
    "        lstm_feats = self._get_lstm_features(sentence)\n",
    "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        return score, tag_seq\n",
    "\n",
    "def make_data_point(sent):\n",
    "    \"\"\"\n",
    "        Creates a dictionary from String to an Array of Strings representing the data.  \n",
    "    \"\"\"\n",
    "    dic = {}\n",
    "    sent = [s.strip().split() for s in sent]\n",
    "    dic['tokens'] = ['<START>'] + [s[0] for s in sent] + ['<STOP>']\n",
    "    dic['pos'] = ['<START>'] + [s[1] for s in sent] + ['<STOP>']\n",
    "    dic['NP_chunk'] = ['<START>'] + [s[2] for s in sent] + ['<STOP>']\n",
    "    dic['gold_tags'] = ['<START>'] + [s[3] for s in sent] + ['<STOP>']\n",
    "    return dic\n",
    "\n",
    "def read_data(filename):\n",
    "    \"\"\"\n",
    "    Reads the CoNLL 2003 data into an array of dictionaries (a dictionary for each data point).\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(filename, 'r') as f:\n",
    "        sent = []\n",
    "        for line in f.readlines():\n",
    "            if line.strip():\n",
    "                sent.append(line)\n",
    "            else:\n",
    "                data.append(make_data_point(sent))\n",
    "                sent = []\n",
    "        data.append(make_data_point(sent))\n",
    "\n",
    "    return data\n",
    "\n",
    "def compute_metrics(predicted_tags, gold_tags):\n",
    "    \"\"\"\n",
    "    Compute precision, recall and F1 score\n",
    "    \"\"\"\n",
    "    # Filter out <START> and <STOP> tags\n",
    "    filtered_pred = []\n",
    "    filtered_gold = []\n",
    "    \n",
    "    for pred_seq, gold_seq in zip(predicted_tags, gold_tags):\n",
    "        # Remove <START> and <STOP> tags\n",
    "        filtered_pred.extend([p for p in pred_seq if p not in [tag_2_idx[START_TAG], tag_2_idx[STOP_TAG]]])\n",
    "        filtered_gold.extend([g for g in gold_seq if g not in [tag_2_idx[START_TAG], tag_2_idx[STOP_TAG]]])\n",
    "    \n",
    "    # Convert indices to tag names for better interpretation\n",
    "    idx_to_tag = {v: k for k, v in tag_2_idx.items()}\n",
    "    pred_tags = [idx_to_tag[i] for i in filtered_pred]\n",
    "    gold_tags = [idx_to_tag[i] for i in filtered_gold]\n",
    "    \n",
    "    # Calculate metrics - exclude 'O' tag or special tags from evaluation if needed\n",
    "    labels = [k for k in tag_2_idx.keys() if k not in [START_TAG, STOP_TAG, 'O']]\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        gold_tags, pred_tags, labels=labels, average='micro')\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "def evaluate_model(model, data, word_2_idx, tag_2_idx):\n",
    "    \"\"\"\n",
    "    Evaluate model on data and return predictions and metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    gold_standards = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for example in data:\n",
    "            sentence = prepare_sequence(example['tokens'], word_2_idx).to(device)\n",
    "            gold_tags = [tag_2_idx[t] for t in example['gold_tags']]\n",
    "            gold_standards.append(gold_tags)\n",
    "            \n",
    "            _, predicted_tags = model(sentence)\n",
    "            predictions.append(predicted_tags)\n",
    "    \n",
    "    precision, recall, f1 = compute_metrics(predictions, gold_standards)\n",
    "    return predictions, precision, recall, f1\n",
    "\n",
    "# Generate output predictions in the required format\n",
    "def generate_output_file(predictions, data, tag_key_list, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for pred_tags, example in zip(predictions, data):\n",
    "            # Convert tag indices to tag names and filter out <START> and <STOP>\n",
    "            tag_names = [tag_key_list[tag_id] for tag_id in pred_tags \n",
    "                         if tag_key_list[tag_id] not in [START_TAG, STOP_TAG]]\n",
    "            \n",
    "            # Make sure we have the same number of tokens and tags\n",
    "            tokens = [t for t in example['tokens'] if t not in [START_TAG, STOP_TAG]]\n",
    "            \n",
    "            # Write output in CoNLL format\n",
    "            for token, tag in zip(tokens, tag_names):\n",
    "                f.write(f\"{token} {tag}\\n\")\n",
    "            f.write(\"\\n\")  # Empty line between sentences\n",
    "\n",
    "def generate_minibatches(training_data, batch_size):\n",
    "    minibatches = []\n",
    "    for i in range(0, len(training_data), batch_size):\n",
    "        minibatch = training_data[i:i + batch_size]\n",
    "        minibatches.append(minibatch)\n",
    "    return minibatches\n",
    "\n",
    "# Constants\n",
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "EMBEDDING_DIM = 40\n",
    "HIDDEN_DIM = 40\n",
    "CHAR_EMBEDDING_DIM = 4\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load data\n",
    "dev_data = read_data('ner.dev')\n",
    "test_data = read_data('ner.test')\n",
    "train_data = read_data('ner.train')\n",
    "print(f\"Train size: {len(train_data)}, Dev size: {len(dev_data)}, Test size: {len(test_data)}\")\n",
    "\n",
    "# Create dictionaries\n",
    "word_2_idx = {}\n",
    "# Add special token for unknown words\n",
    "word_2_idx['<UNK>'] = 0\n",
    "\n",
    "for sentence in train_data + dev_data + test_data:\n",
    "    for word in sentence['tokens']:\n",
    "        if word not in word_2_idx:\n",
    "            word_2_idx[word] = len(word_2_idx)\n",
    "\n",
    "tag_2_idx = {}\n",
    "for sentence in train_data + dev_data + test_data:\n",
    "    for word in sentence['gold_tags']:\n",
    "        if word not in tag_2_idx:\n",
    "            tag_2_idx[word] = len(tag_2_idx)\n",
    "\n",
    "print(f\"Vocabulary size: {len(word_2_idx)}, Tag set size: {len(tag_2_idx)}\")\n",
    "\n",
    "# Initialize tensorboard writer\n",
    "writer = SummaryWriter('runs/structured_svm')\n",
    "\n",
    "# Function to train with structured SVM and early stopping\n",
    "def train_structured_svm(model, train_data, dev_data, learning_rates, reg_strengths, \n",
    "                         cost_scale=10.0, batch_size=32, max_epochs=30, patience=3):\n",
    "    \"\"\"\n",
    "    Train a model using structured SVM with early stopping\n",
    "    \n",
    "    Args:\n",
    "        model: BiLSTM_CRF model\n",
    "        train_data: Training data\n",
    "        dev_data: Development data for early stopping\n",
    "        learning_rates: List of learning rates to try\n",
    "        reg_strengths: List of regularization strengths to try\n",
    "        cost_scale: Scaling factor for hamming distance cost\n",
    "        batch_size: Batch size for training\n",
    "        max_epochs: Maximum number of epochs\n",
    "        patience: Number of epochs to wait for improvement before stopping\n",
    "    \n",
    "    Returns:\n",
    "        best_model: Model with best F1 score\n",
    "        best_lr: Best learning rate\n",
    "        best_reg: Best regularization strength\n",
    "        best_f1: Best F1 score\n",
    "        results: Dictionary of results for each combination\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    best_f1 = 0\n",
    "    best_model = None\n",
    "    best_lr = None\n",
    "    best_reg = None\n",
    "    \n",
    "    # Try different combinations of learning rates and regularization strengths\n",
    "    for lr in learning_rates:\n",
    "        for reg_strength in reg_strengths:\n",
    "            print(f\"\\n=== Training with lr={lr}, reg_strength={reg_strength} ===\")\n",
    "            \n",
    "            # Initialize a new model for each combination\n",
    "            current_model = BiLSTM_CRF(len(word_2_idx), tag_2_idx, EMBEDDING_DIM, HIDDEN_DIM, CHAR_EMBEDDING_DIM)\n",
    "            current_model.to(device)\n",
    "            \n",
    "            # Setup optimizer\n",
    "            optimizer = optim.SGD(current_model.parameters(), lr=lr)\n",
    "            \n",
    "            # Variables for early stopping\n",
    "            best_dev_f1 = 0\n",
    "            epochs_no_improve = 0\n",
    "            epoch_results = []\n",
    "            \n",
    "            for epoch in range(max_epochs):\n",
    "                # Training\n",
    "                current_model.train()\n",
    "                total_loss = 0\n",
    "                minibatches = generate_minibatches(train_data, batch_size)\n",
    "                \n",
    "                for i, minibatch in tqdm(enumerate(minibatches), total=len(minibatches), \n",
    "                                          desc=f\"Epoch {epoch+1}/{max_epochs}\"):\n",
    "                    current_model.zero_grad()\n",
    "                    \n",
    "                    # Calculate loss for each sentence in the batch\n",
    "                    batch_loss = 0\n",
    "                    for sentence in minibatch:\n",
    "                        sentence_in = prepare_sequence(sentence['tokens'], word_2_idx).to(device)\n",
    "                        tags = torch.tensor([tag_2_idx[t] for t in sentence['gold_tags']], \n",
    "                                            dtype=torch.long).to(device)\n",
    "                        \n",
    "                        # Structured SVM loss\n",
    "                        loss = current_model.structured_svm_loss(sentence_in, tags, cost_scale)\n",
    "                        batch_loss += loss\n",
    "                    \n",
    "                    # Average loss over batch\n",
    "                    batch_loss = batch_loss / len(minibatch)\n",
    "                    \n",
    "                    # Add L2 regularization\n",
    "                    l2_reg = 0.0\n",
    "                    for param in current_model.parameters():\n",
    "                        l2_reg += torch.norm(param, 2)\n",
    "                    batch_loss += reg_strength * l2_reg\n",
    "                    \n",
    "                    # Backpropagation\n",
    "                    batch_loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    total_loss += batch_loss.item()\n",
    "                    \n",
    "                    # Log training loss\n",
    "                    writer.add_scalar(f'Loss/train_lr{lr}_reg{reg_strength}', \n",
    "                                      batch_loss.item(), \n",
    "                                      epoch * len(minibatches) + i)\n",
    "                \n",
    "                avg_loss = total_loss / len(minibatches)\n",
    "                print(f\"Epoch {epoch+1}, Average Loss: {avg_loss:.4f}\")\n",
    "                \n",
    "                # Evaluate on dev set\n",
    "                _, dev_precision, dev_recall, dev_f1 = evaluate_model(\n",
    "                    current_model, dev_data, word_2_idx, tag_2_idx)\n",
    "                \n",
    "                print(f\"Dev - Precision: {dev_precision:.4f}, Recall: {dev_recall:.4f}, F1: {dev_f1:.4f}\")\n",
    "                \n",
    "                # Log dev metrics\n",
    "                writer.add_scalar(f'Precision/dev_lr{lr}_reg{reg_strength}', dev_precision, epoch)\n",
    "                writer.add_scalar(f'Recall/dev_lr{lr}_reg{reg_strength}', dev_recall, epoch)\n",
    "                writer.add_scalar(f'F1/dev_lr{lr}_reg{reg_strength}', dev_f1, epoch)\n",
    "                \n",
    "                # Save epoch results\n",
    "                epoch_results.append({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'loss': avg_loss,\n",
    "                    'dev_precision': dev_precision,\n",
    "                    'dev_recall': dev_recall,\n",
    "                    'dev_f1': dev_f1\n",
    "                })\n",
    "                \n",
    "                # Check for improvement\n",
    "                if dev_f1 > best_dev_f1:\n",
    "                    best_dev_f1 = dev_f1\n",
    "                    epochs_no_improve = 0\n",
    "                    # Save model\n",
    "                    torch.save(current_model.state_dict(), \n",
    "                               f'bilstm_crf_svm_lr{lr}_reg{reg_strength}_epoch{epoch+1}.pth')\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    if epochs_no_improve >= patience:\n",
    "                        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                        break\n",
    "            \n",
    "            # Record results for this configuration\n",
    "            results[(lr, reg_strength)] = {\n",
    "                'best_epoch': epoch_results[epoch - epochs_no_improve]['epoch'],\n",
    "                'best_precision': epoch_results[epoch - epochs_no_improve]['dev_precision'],\n",
    "                'best_recall': epoch_results[epoch - epochs_no_improve]['dev_recall'],\n",
    "                'best_f1': epoch_results[epoch - epochs_no_improve]['dev_f1'],\n",
    "                'epoch_results': epoch_results\n",
    "            }\n",
    "            \n",
    "            # Update overall best model if this configuration is better\n",
    "            if best_dev_f1 > best_f1:\n",
    "                best_f1 = best_dev_f1\n",
    "                best_lr = lr\n",
    "                best_reg = reg_strength\n",
    "                \n",
    "                # Load the best model from this configuration\n",
    "                best_model = BiLSTM_CRF(len(word_2_idx), tag_2_idx, EMBEDDING_DIM, HIDDEN_DIM, CHAR_EMBEDDING_DIM)\n",
    "                best_model.load_state_dict(torch.load(\n",
    "                    f'bilstm_crf_svm_lr{lr}_reg{reg_strength}_epoch{epoch_results[epoch - epochs_no_improve][\"epoch\"]}.pth'))\n",
    "                best_model.to(device)\n",
    "    \n",
    "    return best_model, best_lr, best_reg, best_f1, results\n",
    "\n",
    "# Function to plot results\n",
    "def plot_results(results, learning_rates, reg_strengths):\n",
    "    \"\"\"\n",
    "    Plot results of parameter tuning\n",
    "    \"\"\"\n",
    "    # Create a matrix of F1 scores\n",
    "    f1_matrix = np.zeros((len(learning_rates), len(reg_strengths)))\n",
    "    \n",
    "    for i, lr in enumerate(learning_rates):\n",
    "        for j, reg in enumerate(reg_strengths):\n",
    "            f1_matrix[i, j] = results.get((lr, reg), {}).get('best_f1', 0)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(f1_matrix, interpolation='nearest', cmap='viridis')\n",
    "    plt.title('F1 Score by Learning Rate and Regularization Strength')\n",
    "    plt.xlabel('Regularization Strength')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    \n",
    "    # Add colorbar\n",
    "    plt.colorbar(label='F1 Score')\n",
    "    \n",
    "    # Add axis labels\n",
    "    plt.xticks(np.arange(len(reg_strengths)), reg_strengths)\n",
    "    plt.yticks(np.arange(len(learning_rates)), learning_rates)\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i in range(len(learning_rates)):\n",
    "        for j in range(len(reg_strengths)):\n",
    "            plt.text(j, i, f'{f1_matrix[i, j]:.3f}', \n",
    "                     ha=\"center\", va=\"center\", color=\"white\" if f1_matrix[i, j] < 0.5 else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('parameter_tuning_results.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot precision, recall, and F1 for best configuration\n",
    "    best_lr, best_reg = max(results.keys(), key=lambda k: results[k]['best_f1'])\n",
    "    epoch_results = results[(best_lr, best_reg)]['epoch_results']\n",
    "    \n",
    "    epochs = [r['epoch'] for r in epoch_results]\n",
    "    precision = [r['dev_precision'] for r in epoch_results]\n",
    "    recall = [r['dev_recall'] for r in epoch_results]\n",
    "    f1 = [r['dev_f1'] for r in epoch_results]\n",
    "    loss = [r['loss'] for r in epoch_results]\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, precision, marker='o', label='Precision')\n",
    "    plt.plot(epochs, recall, marker='s', label='Recall')\n",
    "    plt.plot(epochs, f1, marker='^', label='F1')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title(f'Metrics (lr={best_lr}, reg={best_reg})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss, marker='o', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('best_model_training_curves.png')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training with lr=0.001, reg_strength=0.01 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 30/30 [12:44<00:00, 25.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 20612.8199\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [51578, 58510]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m reg_strengths = [\u001b[32m0.01\u001b[39m, \u001b[32m0.001\u001b[39m, \u001b[32m0.05\u001b[39m]\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Train model with structured SVM and early stopping\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m best_model, best_lr, best_reg, best_f1, results = \u001b[43mtrain_structured_svm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg_strengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcost_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\n\u001b[32m     13\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Print tuning results\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mParameter Tuning Results:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 401\u001b[39m, in \u001b[36mtrain_structured_svm\u001b[39m\u001b[34m(model, train_data, dev_data, learning_rates, reg_strengths, cost_scale, batch_size, max_epochs, patience)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Average Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    400\u001b[39m \u001b[38;5;66;03m# Evaluate on dev set\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m _, dev_precision, dev_recall, dev_f1 = \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcurrent_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_2_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtag_2_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDev - Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdev_precision\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdev_recall\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, F1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdev_f1\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    406\u001b[39m \u001b[38;5;66;03m# Log dev metrics\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 245\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, data, word_2_idx, tag_2_idx)\u001b[39m\n\u001b[32m    242\u001b[39m         _, predicted_tags = model(sentence)\n\u001b[32m    243\u001b[39m         predictions.append(predicted_tags)\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m precision, recall, f1 = \u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgold_standards\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m predictions, precision, recall, f1\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 223\u001b[39m, in \u001b[36mcompute_metrics\u001b[39m\u001b[34m(predicted_tags, gold_tags)\u001b[39m\n\u001b[32m    220\u001b[39m \u001b[38;5;66;03m# Calculate metrics - exclude 'O' tag or special tags from evaluation if needed\u001b[39;00m\n\u001b[32m    221\u001b[39m labels = [k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m tag_2_idx.keys() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [START_TAG, STOP_TAG, \u001b[33m'\u001b[39m\u001b[33mO\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m precision, recall, f1, _ = \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgold_tags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_tags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmicro\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m precision, recall, f1\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/203A3E1/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/203A3E1/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1830\u001b[39m, in \u001b[36mprecision_recall_fscore_support\u001b[39m\u001b[34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[39m\n\u001b[32m   1661\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[32m   1662\u001b[39m \n\u001b[32m   1663\u001b[39m \u001b[33;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1827\u001b[39m \u001b[33;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[32m   1828\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1829\u001b[39m _check_zero_division(zero_division)\n\u001b[32m-> \u001b[39m\u001b[32m1830\u001b[39m labels = \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1832\u001b[39m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[32m   1833\u001b[39m samplewise = average == \u001b[33m\"\u001b[39m\u001b[33msamples\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/203A3E1/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1596\u001b[39m, in \u001b[36m_check_set_wise_labels\u001b[39m\u001b[34m(y_true, y_pred, average, labels, pos_label)\u001b[39m\n\u001b[32m   1593\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33maverage has to be one of \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[32m   1595\u001b[39m y_true, y_pred = attach_unique(y_true, y_pred)\n\u001b[32m-> \u001b[39m\u001b[32m1596\u001b[39m y_type, y_true, y_pred = \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1597\u001b[39m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[32m   1598\u001b[39m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[32m   1599\u001b[39m present_labels = _tolist(unique_labels(y_true, y_pred))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/203A3E1/lib/python3.13/site-packages/sklearn/metrics/_classification.py:98\u001b[39m, in \u001b[36m_check_targets\u001b[39m\u001b[34m(y_true, y_pred)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[32m     72\u001b[39m \n\u001b[32m     73\u001b[39m \u001b[33;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     95\u001b[39m \u001b[33;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     97\u001b[39m xp, _ = get_namespace(y_true, y_pred)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m type_true = type_of_target(y_true, input_name=\u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    100\u001b[39m type_pred = type_of_target(y_pred, input_name=\u001b[33m\"\u001b[39m\u001b[33my_pred\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/203A3E1/lib/python3.13/site-packages/sklearn/utils/validation.py:475\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    473\u001b[39m uniques = np.unique(lengths)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    476\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    477\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    478\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [51578, 58510]"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters to tune\n",
    "    learning_rates = [0.001]\n",
    "    reg_strengths = [0.01, 0.001, 0.05]\n",
    "    \n",
    "    # Train model with structured SVM and early stopping\n",
    "    best_model, best_lr, best_reg, best_f1, results = train_structured_svm(\n",
    "        None, train_data, dev_data, \n",
    "        learning_rates, reg_strengths, \n",
    "        cost_scale=10.0, batch_size=512, \n",
    "        max_epochs=5, patience=2\n",
    "    )\n",
    "    \n",
    "    # Print tuning results\n",
    "    print(\"\\nParameter Tuning Results:\")\n",
    "    for (lr, reg), result in results.items():\n",
    "        print(f\"lr={lr}, reg={reg}: Precision={result['best_precision']:.4f}, \"\n",
    "              f\"Recall={result['best_recall']:.4f}, F1={result['best_f1']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nBest Configuration: lr={best_lr}, reg={best_reg}, F1={best_f1:.4f}\")\n",
    "    \n",
    "    # Plot results\n",
    "    plot_results(results, learning_rates, reg_strengths)\n",
    "    \n",
    "    # Evaluate best model on test set\n",
    "    print(\"\\nEvaluating best model on test set...\")\n",
    "    test_preds, test_precision, test_recall, test_f1 = evaluate_model(\n",
    "        best_model, test_data, word_2_idx, tag_2_idx)\n",
    "    \n",
    "    print(f\"Test Results: Precision={test_precision:.4f}, Recall={test_recall:.4f}, F1={test_f1:.4f}\")\n",
    "    \n",
    "    # Generate output files\n",
    "    tag_key_list = list(tag_2_idx.keys())\n",
    "    \n",
    "    # Get predictions for dev set\n",
    "    dev_preds, _, _, _ = evaluate_model(best_model, dev_data, word_2_idx, tag_2_idx)\n",
    "    \n",
    "    # Generate output files\n",
    "    generate_output_file(dev_preds, dev_data, tag_key_list, 'dev_predictions_svm.txt')\n",
    "    generate_output_file(test_preds, test_data, tag_key_list, 'test_predictions_svm.txt')\n",
    "    \n",
    "    # Save best model\n",
    "    torch.save(best_model.state_dict(), 'best_bilstm_crf_svm_model.pth')\n",
    "    \n",
    "    # Generate report\n",
    "    with open('structured_svm_report.txt', 'w') as f:\n",
    "        f.write(\"# Structured SVM Training Report\\n\\n\")\n",
    "        \n",
    "        f.write(\"## Model Description\\n\")\n",
    "        f.write(\"The model is a BiLSTM-CRF with structured SVM training using a Hamming distance cost function.\\n\")\n",
    "        f.write(f\"- Embedding dimension: {EMBEDDING_DIM}\\n\")\n",
    "        f.write(f\"- Hidden dimension: {HIDDEN_DIM}\\n\")\n",
    "        f.write(f\"- Cost scale: 10.0 (multiplier for Hamming distance)\\n\\n\")\n",
    "        \n",
    "        f.write(\"## Training Details\\n\")\n",
    "        f.write(\"- Implemented early stopping based on F1 score on dev set\\n\")\n",
    "        f.write(\"- Used L2 regularization\\n\")\n",
    "        f.write(\"- Cost-augmented decoding during training\\n\\n\")\n",
    "        \n",
    "        f.write(\"## Parameter Tuning Results\\n\")\n",
    "        f.write(\"| Learning Rate | Reg Strength | Precision | Recall | F1 |\\n\")\n",
    "        f.write(\"|---------------|--------------|-----------|--------|----|\\n\")\n",
    "        \n",
    "        for (lr, reg), result in results.items():\n",
    "            f.write(f\"| {lr} | {reg} | {result['best_precision']:.4f} | {result['best_recall']:.4f} | {result['best_f1']:.4f} |\\n\")\n",
    "        \n",
    "        f.write(f\"\\nBest configuration: lr={best_lr}, reg={best_reg}, F1={best_f1:.4f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"## Final Results\\n\")\n",
    "        f.write(f\"Dev set: Precision={best_f1:.4f}, Recall={results[(best_lr, best_reg)]['best_recall']:.4f}, F1={results[(best_lr, best_reg)]['best_f1']:.4f}\\n\")\n",
    "        f.write(f\"Test set: Precision={test_precision:.4f}, Recall={test_recall:.4f}, F1={test_f1:.4f}\\n\")\n",
    "        \n",
    "    print(\"Done! See structured_svm_report.txt for complete results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Train size: 14987, Dev size: 3466, Test size: 3684\n",
      "Vocabulary size: 23627, Tag set size: 10\n",
      "\n",
      "=== Training with lr=0.001, reg_strength=0.01 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 15/15 [11:50<00:00, 47.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 20604.8952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3466/3466 [00:29<00:00, 118.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev - Precision: 0.0452, Recall: 0.1695, F1: 0.0714\n",
      "Model saved to bilstm_crf_svm_lr0.001_reg0.01_epoch1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 15/15 [11:50<00:00, 47.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 20600.7046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3466/3466 [00:29<00:00, 118.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev - Precision: 0.0957, Recall: 0.0378, F1: 0.0542\n",
      "Early stopping at epoch 2\n",
      "\n",
      "=== Training with lr=0.001, reg_strength=0.001 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 15/15 [11:50<00:00, 47.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 20231.9301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3466/3466 [00:29<00:00, 118.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev - Precision: 0.0238, Recall: 0.1430, F1: 0.0409\n",
      "Model saved to bilstm_crf_svm_lr0.001_reg0.001_epoch1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 15/15 [11:52<00:00, 47.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 20225.9436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3466/3466 [00:29<00:00, 117.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev - Precision: 0.0241, Recall: 0.1447, F1: 0.0414\n",
      "Model saved to bilstm_crf_svm_lr0.001_reg0.001_epoch2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 15/15 [11:51<00:00, 47.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average Loss: 20220.0174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3466/3466 [00:28<00:00, 119.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev - Precision: 0.0242, Recall: 0.1447, F1: 0.0415\n",
      "Model saved to bilstm_crf_svm_lr0.001_reg0.001_epoch3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 15/15 [11:57<00:00, 47.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Average Loss: 20214.1664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3466/3466 [00:30<00:00, 115.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev - Precision: 0.0243, Recall: 0.1431, F1: 0.0415\n",
      "Model saved to bilstm_crf_svm_lr0.001_reg0.001_epoch4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 15/15 [10:53<00:00, 43.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Average Loss: 20208.4385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3466/3466 [00:30<00:00, 115.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev - Precision: 0.0267, Recall: 0.1420, F1: 0.0450\n",
      "Model saved to bilstm_crf_svm_lr0.001_reg0.001_epoch5.pth\n",
      "\n",
      "=== Training with lr=0.001, reg_strength=0.05 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 15/15 [10:55<00:00, 43.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 22382.2596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3466/3466 [00:39<00:00, 87.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev - Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "Early stopping at epoch 1\n",
      "\n",
      "Parameter Tuning Results:\n",
      "lr=0.001, reg=0.01: Precision=0.0452, Recall=0.1695, F1=0.0714\n",
      "lr=0.001, reg=0.001: Precision=0.0267, Recall=0.1420, F1=0.0450\n",
      "lr=0.001, reg=0.05: Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "\n",
      "Best Configuration: lr=0.001, reg=0.01, F1=0.0714\n",
      "\n",
      "Evaluating best model on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3684/3684 [00:37<00:00, 99.43it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results: Precision=0.0450, Recall=0.1590, F1=0.0702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3466/3466 [00:39<00:00, 87.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! See structured_svm_report.txt for complete results.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def argmax(vec):\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n",
    "\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix.get(w, to_ix.get('<UNK>', 0)) for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + \\\n",
    "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
    "\n",
    "\n",
    "# Hamming distance calculation\n",
    "def hamming_distance(y_pred, y_gold):\n",
    "    \"\"\"Calculate hamming distance between predicted and gold sequences\"\"\"\n",
    "    return sum(y1 != y2 for y1, y2 in zip(y_pred, y_gold))\n",
    "\n",
    "\n",
    "class BiLSTM_CRF(nn.Module): \n",
    "\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim, char_embedding_dim):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "\n",
    "        self.transitions = nn.Parameter(\n",
    "            torch.randn(self.tagset_size, self.tagset_size))\n",
    "\n",
    "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "        self.hidden = self.init_hidden()\n",
    "        self.char_embed = nn.Embedding(10, char_embedding_dim)\n",
    "        self.char_cnn = nn.Conv2d(in_channels=1, out_channels=char_embedding_dim, kernel_size=(1, char_embedding_dim))\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(2, 1, self.hidden_dim // 2),\n",
    "                torch.randn(2, 1, self.hidden_dim // 2))\n",
    "\n",
    "    def _forward_alg(self, feats):\n",
    "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
    "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
    "\n",
    "        forward_var = init_alphas\n",
    "        device_info = feats.device \n",
    "        forward_var = forward_var.to(device_info)\n",
    "        \n",
    "        for feat in feats:\n",
    "            alphas_t = []  \n",
    "            for next_tag in range(self.tagset_size):\n",
    "                emit_score = feat[next_tag].view(\n",
    "                    1, -1).expand(1, self.tagset_size)\n",
    "                trans_score = self.transitions[next_tag].view(1, -1)\n",
    "                next_tag_var = forward_var + trans_score + emit_score\n",
    "         \n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        return alpha\n",
    "\n",
    "    def _get_lstm_features(self, sentence): \n",
    "        self.hidden = self.init_hidden()\n",
    "        sentence = sentence.to(self.word_embeds.weight.device)\n",
    "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
    "        self.hidden = tuple(h.to(embeds.device) for h in self.hidden)\n",
    "        lstm_out, self.hidden = self.lstm(embeds, self.hidden) \n",
    "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "        return lstm_feats\n",
    "\n",
    "    def _score_sentence(self, feats, tags):\n",
    "        score = torch.zeros(1, device=feats.device)\n",
    "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long, device=feats.device), tags])\n",
    "        for i, feat in enumerate(feats):\n",
    "            score = score + \\\n",
    "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "\n",
    "    def _viterbi_decode(self, feats, gold_tags=None, cost_scale=0):\n",
    "        \"\"\"\n",
    "        Run Viterbi algorithm to get the best tag sequence.\n",
    "        With cost_scale > 0, it performs cost-augmented inference.\n",
    "        \"\"\"\n",
    "        backpointers = []\n",
    "\n",
    "        init_vvars = torch.full((1, self.tagset_size), -10000., device=feats.device)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "\n",
    "        forward_var = init_vvars\n",
    "        for i, feat in enumerate(feats):\n",
    "            bptrs_t = [] \n",
    "            viterbivars_t = []  \n",
    "\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                \n",
    "                # Cost-augmented decoding: add cost when gold and predicted tags differ\n",
    "                if cost_scale > 0 and gold_tags is not None and i < len(gold_tags):\n",
    "                    cost = torch.zeros(self.tagset_size, device=feats.device)\n",
    "                    # No cost for correct tag\n",
    "                    # 10x cost (hamming distance) for incorrect tags\n",
    "                    mask = torch.ones(self.tagset_size, device=feats.device)\n",
    "                    mask[gold_tags[i]] = 0\n",
    "                    cost = cost_scale * mask  # Apply cost to incorrect tags\n",
    "                    next_tag_var = next_tag_var + cost\n",
    "                \n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            \n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        best_tag_id = argmax(terminal_var)\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag_to_ix[START_TAG]\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def structured_svm_loss(self, sentence, tags, cost_scale=10.0):\n",
    "        \"\"\"\n",
    "        Structured SVM loss with cost-augmented decoding.\n",
    "        L(x,y,w) = max_{y'} [score(x,y',w) + cost(y,y')] - score(x,y,w)\n",
    "        \"\"\"\n",
    "        feats = self._get_lstm_features(sentence)\n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "        \n",
    "        # Convert tags tensor to list for cost-augmented decoding\n",
    "        gold_tags_list = tags.cpu().tolist()\n",
    "        \n",
    "        # Cost-augmented decoding\n",
    "        cost_augmented_score, predicted_tags = self._viterbi_decode(feats, gold_tags_list, cost_scale)\n",
    "        \n",
    "        # Margin-based loss\n",
    "        margin = cost_augmented_score - gold_score\n",
    "        \n",
    "        return margin if margin > 0 else torch.zeros_like(margin)\n",
    "\n",
    "    def forward(self, sentence):  \n",
    "        lstm_feats = self._get_lstm_features(sentence)\n",
    "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        return score, tag_seq\n",
    "\n",
    "def make_data_point(sent):\n",
    "    \"\"\"\n",
    "        Creates a dictionary from String to an Array of Strings representing the data.  \n",
    "    \"\"\"\n",
    "    dic = {}\n",
    "    sent = [s.strip().split() for s in sent]\n",
    "    dic['tokens'] = ['<START>'] + [s[0] for s in sent] + ['<STOP>']\n",
    "    dic['pos'] = ['<START>'] + [s[1] for s in sent] + ['<STOP>']\n",
    "    dic['NP_chunk'] = ['<START>'] + [s[2] for s in sent] + ['<STOP>']\n",
    "    dic['gold_tags'] = ['<START>'] + [s[3] for s in sent] + ['<STOP>']\n",
    "    return dic\n",
    "\n",
    "def read_data(filename):\n",
    "    \"\"\"\n",
    "    Reads the CoNLL 2003 data into an array of dictionaries (a dictionary for each data point).\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(filename, 'r') as f:\n",
    "        sent = []\n",
    "        for line in f.readlines():\n",
    "            if line.strip():\n",
    "                sent.append(line)\n",
    "            else:\n",
    "                data.append(make_data_point(sent))\n",
    "                sent = []\n",
    "        data.append(make_data_point(sent))\n",
    "\n",
    "    return data\n",
    "\n",
    "def compute_metrics(predictions, gold_standards, tag_2_idx):\n",
    "    \"\"\"\n",
    "    Compute precision, recall and F1 score\n",
    "    \n",
    "    This version handles different lengths safely by truncating or padding as needed\n",
    "    \"\"\"\n",
    "    idx_to_tag = {v: k for k, v in tag_2_idx.items()}\n",
    "    \n",
    "    filtered_pred = []\n",
    "    filtered_gold = []\n",
    "    \n",
    "    # Handle different sequence lengths appropriately\n",
    "    for pred_seq, gold_seq in zip(predictions, gold_standards):\n",
    "        # Filter out special tags and convert to actual tag names\n",
    "        pred_tags = [idx_to_tag[idx] for idx in pred_seq \n",
    "                    if idx_to_tag[idx] not in [START_TAG, STOP_TAG]]\n",
    "        gold_tags = [idx_to_tag[idx] for idx in gold_seq \n",
    "                    if idx_to_tag[idx] not in [START_TAG, STOP_TAG]]\n",
    "        \n",
    "        # Handle different lengths: truncate to the shorter length\n",
    "        min_len = min(len(pred_tags), len(gold_tags))\n",
    "        pred_tags = pred_tags[:min_len]\n",
    "        gold_tags = gold_tags[:min_len]\n",
    "        \n",
    "        filtered_pred.extend(pred_tags)\n",
    "        filtered_gold.extend(gold_tags)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    labels = [k for k in tag_2_idx.keys() if k not in [START_TAG, STOP_TAG, 'O']]\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        filtered_gold, filtered_pred, labels=labels, average='micro', zero_division=0)\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "def evaluate_model(model, data, word_2_idx, tag_2_idx):\n",
    "    \"\"\"\n",
    "    Evaluate model on data and return predictions and metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    gold_standards = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for example in tqdm(data, desc=\"Evaluating\"):\n",
    "            # Prepare sentence and gold tags\n",
    "            sentence = prepare_sequence(example['tokens'], word_2_idx).to(next(model.parameters()).device)\n",
    "            gold_tags = [tag_2_idx[t] for t in example['gold_tags']]\n",
    "            gold_standards.append(gold_tags)\n",
    "            \n",
    "            # Get predictions\n",
    "            _, predicted_tags = model(sentence)\n",
    "            predictions.append(predicted_tags)\n",
    "    \n",
    "    precision, recall, f1 = compute_metrics(predictions, gold_standards, tag_2_idx)\n",
    "    return predictions, precision, recall, f1\n",
    "\n",
    "def generate_output_file(predictions, data, tag_2_idx, filename):\n",
    "    \"\"\"\n",
    "    Generate output file in the required format\n",
    "    \"\"\"\n",
    "    idx_to_tag = {v: k for k, v in tag_2_idx.items()}\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        for pred_tags, example in zip(predictions, data):\n",
    "            # Convert tag indices to tag names\n",
    "            tag_names = [idx_to_tag[tag_id] for tag_id in pred_tags \n",
    "                         if idx_to_tag[tag_id] not in [START_TAG, STOP_TAG]]\n",
    "            \n",
    "            # Get tokens (excluding special tokens)\n",
    "            tokens = [t for t in example['tokens'] if t not in [START_TAG, STOP_TAG]]\n",
    "            \n",
    "            # Ensure lengths match by truncating to shorter length\n",
    "            min_len = min(len(tokens), len(tag_names))\n",
    "            tokens = tokens[:min_len]\n",
    "            tag_names = tag_names[:min_len]\n",
    "            \n",
    "            # Write in the required format\n",
    "            for token, tag in zip(tokens, tag_names):\n",
    "                f.write(f\"{token} {tag}\\n\")\n",
    "            f.write(\"\\n\")  # Empty line between sentences\n",
    "\n",
    "def generate_minibatches(training_data, batch_size):\n",
    "    \"\"\"\n",
    "    Generate minibatches for training\n",
    "    \"\"\"\n",
    "    # Shuffle data first for better training\n",
    "    indices = list(range(len(training_data)))\n",
    "    np.random.shuffle(indices)\n",
    "    shuffled_data = [training_data[i] for i in indices]\n",
    "    \n",
    "    minibatches = []\n",
    "    for i in range(0, len(shuffled_data), batch_size):\n",
    "        minibatch = shuffled_data[i:i + batch_size]\n",
    "        minibatches.append(minibatch)\n",
    "    return minibatches\n",
    "\n",
    "# Constants\n",
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "EMBEDDING_DIM = 40\n",
    "HIDDEN_DIM = 40\n",
    "CHAR_EMBEDDING_DIM = 4\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load data\n",
    "dev_data = read_data('ner.dev')\n",
    "test_data = read_data('ner.test')\n",
    "train_data = read_data('ner.train')\n",
    "print(f\"Train size: {len(train_data)}, Dev size: {len(dev_data)}, Test size: {len(test_data)}\")\n",
    "\n",
    "# Create dictionaries\n",
    "word_2_idx = {}\n",
    "# Add special token for unknown words\n",
    "word_2_idx['<UNK>'] = 0\n",
    "\n",
    "for sentence in train_data:\n",
    "    for word in sentence['tokens']:\n",
    "        if word not in word_2_idx:\n",
    "            word_2_idx[word] = len(word_2_idx)\n",
    "\n",
    "tag_2_idx = {}\n",
    "for sentence in train_data + dev_data + test_data:\n",
    "    for word in sentence['gold_tags']:\n",
    "        if word not in tag_2_idx:\n",
    "            tag_2_idx[word] = len(tag_2_idx)\n",
    "\n",
    "print(f\"Vocabulary size: {len(word_2_idx)}, Tag set size: {len(tag_2_idx)}\")\n",
    "\n",
    "# Initialize tensorboard writer\n",
    "writer = SummaryWriter('runs/structured_svm')\n",
    "\n",
    "# Function to train with structured SVM and early stopping\n",
    "def train_structured_svm(model, train_data, dev_data, learning_rates, reg_strengths, \n",
    "                         cost_scale=10.0, batch_size=32, max_epochs=30, patience=3):\n",
    "    \"\"\"\n",
    "    Train a model using structured SVM with early stopping\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    best_f1 = 0\n",
    "    best_model = None\n",
    "    best_lr = None\n",
    "    best_reg = None\n",
    "    \n",
    "    # Try different combinations of learning rates and regularization strengths\n",
    "    for lr in learning_rates:\n",
    "        for reg_strength in reg_strengths:\n",
    "            print(f\"\\n=== Training with lr={lr}, reg_strength={reg_strength} ===\")\n",
    "            \n",
    "            # Initialize a new model for each combination\n",
    "            current_model = BiLSTM_CRF(len(word_2_idx), tag_2_idx, EMBEDDING_DIM, HIDDEN_DIM, CHAR_EMBEDDING_DIM)\n",
    "            current_model.to(device)\n",
    "            \n",
    "            # Setup optimizer\n",
    "            optimizer = optim.SGD(current_model.parameters(), lr=lr)\n",
    "            \n",
    "            # Variables for early stopping\n",
    "            best_dev_f1 = 0\n",
    "            epochs_no_improve = 0\n",
    "            epoch_results = []\n",
    "            \n",
    "            for epoch in range(max_epochs):\n",
    "                # Training\n",
    "                current_model.train()\n",
    "                total_loss = 0\n",
    "                minibatches = generate_minibatches(train_data, batch_size)\n",
    "                \n",
    "                for i, minibatch in enumerate(tqdm(minibatches, desc=f\"Epoch {epoch+1}/{max_epochs}\")):\n",
    "                    current_model.zero_grad()\n",
    "                    \n",
    "                    # Calculate loss for each sentence in the batch\n",
    "                    batch_loss = 0\n",
    "                    for sentence in minibatch:\n",
    "                        # Skip empty sentences if any\n",
    "                        if len(sentence['tokens']) <= 2:  # Only START and STOP\n",
    "                            continue\n",
    "                            \n",
    "                        sentence_in = prepare_sequence(sentence['tokens'], word_2_idx).to(device)\n",
    "                        tags = torch.tensor([tag_2_idx[t] for t in sentence['gold_tags']], \n",
    "                                            dtype=torch.long).to(device)\n",
    "                        \n",
    "                        # Skip if lengths don't match (should not happen)\n",
    "                        if len(sentence_in) != len(tags):\n",
    "                            print(f\"Warning: Sentence length mismatch: {len(sentence_in)} vs {len(tags)}\")\n",
    "                            continue\n",
    "                        \n",
    "                        # Structured SVM loss\n",
    "                        loss = current_model.structured_svm_loss(sentence_in, tags, cost_scale)\n",
    "                        batch_loss += loss\n",
    "                    \n",
    "                    # Skip empty batches\n",
    "                    if batch_loss == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    # Average loss over batch\n",
    "                    batch_loss = batch_loss / len(minibatch)\n",
    "                    \n",
    "                    # Add L2 regularization\n",
    "                    l2_reg = 0.0\n",
    "                    for param in current_model.parameters():\n",
    "                        l2_reg += torch.norm(param, 2)\n",
    "                    batch_loss += reg_strength * l2_reg\n",
    "                    \n",
    "                    # Backpropagation\n",
    "                    batch_loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    total_loss += batch_loss.item()\n",
    "                    \n",
    "                    # Log training loss\n",
    "                    writer.add_scalar(f'Loss/train_lr{lr}_reg{reg_strength}', \n",
    "                                      batch_loss.item(), \n",
    "                                      epoch * len(minibatches) + i)\n",
    "                \n",
    "                avg_loss = total_loss / len(minibatches) if minibatches else 0\n",
    "                print(f\"Epoch {epoch+1}, Average Loss: {avg_loss:.4f}\")\n",
    "                \n",
    "                # Evaluate on dev set\n",
    "                dev_preds, dev_precision, dev_recall, dev_f1 = evaluate_model(\n",
    "                    current_model, dev_data, word_2_idx, tag_2_idx)\n",
    "                \n",
    "                print(f\"Dev - Precision: {dev_precision:.4f}, Recall: {dev_recall:.4f}, F1: {dev_f1:.4f}\")\n",
    "                \n",
    "                # Log dev metrics\n",
    "                writer.add_scalar(f'Precision/dev_lr{lr}_reg{reg_strength}', dev_precision, epoch)\n",
    "                writer.add_scalar(f'Recall/dev_lr{lr}_reg{reg_strength}', dev_recall, epoch)\n",
    "                writer.add_scalar(f'F1/dev_lr{lr}_reg{reg_strength}', dev_f1, epoch)\n",
    "                \n",
    "                # Save epoch results\n",
    "                epoch_results.append({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'loss': avg_loss,\n",
    "                    'dev_precision': dev_precision,\n",
    "                    'dev_recall': dev_recall,\n",
    "                    'dev_f1': dev_f1\n",
    "                })\n",
    "                \n",
    "                # Check for improvement\n",
    "                if dev_f1 > best_dev_f1:\n",
    "                    best_dev_f1 = dev_f1\n",
    "                    epochs_no_improve = 0\n",
    "                    # Save model\n",
    "                    model_path = f'bilstm_crf_svm_lr{lr}_reg{reg_strength}_epoch{epoch+1}.pth'\n",
    "                    torch.save(current_model.state_dict(), model_path)\n",
    "                    print(f\"Model saved to {model_path}\")\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    if epochs_no_improve >= patience:\n",
    "                        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                        break\n",
    "            \n",
    "            # Get best epoch result\n",
    "            best_epoch_idx = max(range(len(epoch_results)), \n",
    "                                key=lambda i: epoch_results[i]['dev_f1'])\n",
    "            best_epoch_result = epoch_results[best_epoch_idx]\n",
    "            \n",
    "            # Record results for this configuration\n",
    "            results[(lr, reg_strength)] = {\n",
    "                'best_epoch': best_epoch_result['epoch'],\n",
    "                'best_precision': best_epoch_result['dev_precision'],\n",
    "                'best_recall': best_epoch_result['dev_recall'],\n",
    "                'best_f1': best_epoch_result['dev_f1'],\n",
    "                'epoch_results': epoch_results\n",
    "            }\n",
    "            \n",
    "            # Update overall best model if this configuration is better\n",
    "            if best_epoch_result['dev_f1'] > best_f1:\n",
    "                best_f1 = best_epoch_result['dev_f1']\n",
    "                best_lr = lr\n",
    "                best_reg = reg_strength\n",
    "                \n",
    "                # Load the best model from this configuration\n",
    "                best_model = BiLSTM_CRF(len(word_2_idx), tag_2_idx, EMBEDDING_DIM, HIDDEN_DIM, CHAR_EMBEDDING_DIM)\n",
    "                best_model.load_state_dict(torch.load(\n",
    "                    f'bilstm_crf_svm_lr{lr}_reg{reg_strength}_epoch{best_epoch_result[\"epoch\"]}.pth'))\n",
    "                best_model.to(device)\n",
    "    \n",
    "    return best_model, best_lr, best_reg, best_f1, results\n",
    "\n",
    "# Function to plot results\n",
    "def plot_results(results, learning_rates, reg_strengths):\n",
    "    \"\"\"\n",
    "    Plot results of parameter tuning\n",
    "    \"\"\"\n",
    "    # Create a matrix of F1 scores\n",
    "    f1_matrix = np.zeros((len(learning_rates), len(reg_strengths)))\n",
    "    \n",
    "    for i, lr in enumerate(learning_rates):\n",
    "        for j, reg in enumerate(reg_strengths):\n",
    "            f1_matrix[i, j] = results.get((lr, reg), {}).get('best_f1', 0)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(f1_matrix, interpolation='nearest', cmap='viridis')\n",
    "    plt.title('F1 Score by Learning Rate and Regularization Strength')\n",
    "    plt.xlabel('Regularization Strength')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    \n",
    "    # Add colorbar\n",
    "    plt.colorbar(label='F1 Score')\n",
    "    \n",
    "    # Add axis labels\n",
    "    plt.xticks(np.arange(len(reg_strengths)), reg_strengths)\n",
    "    plt.yticks(np.arange(len(learning_rates)), learning_rates)\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i in range(len(learning_rates)):\n",
    "        for j in range(len(reg_strengths)):\n",
    "            plt.text(j, i, f'{f1_matrix[i, j]:.3f}', \n",
    "                     ha=\"center\", va=\"center\", color=\"white\" if f1_matrix[i, j] < 0.5 else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('parameter_tuning_results.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot precision, recall, and F1 for best configuration\n",
    "    best_config = max(results.keys(), key=lambda k: results[k]['best_f1'])\n",
    "    if best_config:\n",
    "        best_lr, best_reg = best_config\n",
    "        epoch_results = results[(best_lr, best_reg)]['epoch_results']\n",
    "        \n",
    "        epochs = [r['epoch'] for r in epoch_results]\n",
    "        precision = [r['dev_precision'] for r in epoch_results]\n",
    "        recall = [r['dev_recall'] for r in epoch_results]\n",
    "        f1 = [r['dev_f1'] for r in epoch_results]\n",
    "        loss = [r['loss'] for r in epoch_results]\n",
    "        \n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs, precision, marker='o', label='Precision')\n",
    "        plt.plot(epochs, recall, marker='s', label='Recall')\n",
    "        plt.plot(epochs, f1, marker='^', label='F1')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title(f'Metrics (lr={best_lr}, reg={best_reg})')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs, loss, marker='o', color='red')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('best_model_training_curves.png')\n",
    "        plt.close()\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters to tune - using more conservative values\n",
    "    learning_rates = [0.001]\n",
    "    reg_strengths = [0.01, 0.001, 0.05]\n",
    "    \n",
    "    # Train model with structured SVM and early stopping\n",
    "    best_model, best_lr, best_reg, best_f1, results = train_structured_svm(\n",
    "        None, train_data, dev_data, \n",
    "        learning_rates, reg_strengths, \n",
    "        cost_scale=10.0, batch_size=1024,  \n",
    "        max_epochs=5, patience=1\n",
    "    )\n",
    "    \n",
    "    # Print tuning results\n",
    "    print(\"\\nParameter Tuning Results:\")\n",
    "    for (lr, reg), result in results.items():\n",
    "        print(f\"lr={lr}, reg={reg}: Precision={result['best_precision']:.4f}, \"\n",
    "              f\"Recall={result['best_recall']:.4f}, F1={result['best_f1']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nBest Configuration: lr={best_lr}, reg={best_reg}, F1={best_f1:.4f}\")\n",
    "    \n",
    "    # Plot results\n",
    "    plot_results(results, learning_rates, reg_strengths)\n",
    "    \n",
    "    # Evaluate best model on test set\n",
    "    print(\"\\nEvaluating best model on test set...\")\n",
    "    test_preds, test_precision, test_recall, test_f1 = evaluate_model(\n",
    "        best_model, test_data, word_2_idx, tag_2_idx)\n",
    "    \n",
    "    print(f\"Test Results: Precision={test_precision:.4f}, Recall={test_recall:.4f}, F1={test_f1:.4f}\")\n",
    "    \n",
    "    # Generate output files\n",
    "    # Get predictions for dev set\n",
    "    dev_preds, _, _, _ = evaluate_model(best_model, dev_data, word_2_idx, tag_2_idx)\n",
    "    \n",
    "    # Generate output files\n",
    "    generate_output_file(dev_preds, dev_data, tag_2_idx, 'dev_predictions_svm.txt')\n",
    "    generate_output_file(test_preds, test_data, tag_2_idx, 'test_predictions_svm.txt')\n",
    "    \n",
    "    # Save best model\n",
    "    torch.save(best_model.state_dict(), 'best_bilstm_crf_svm_model.pth')\n",
    "    \n",
    "    # Generate report\n",
    "    with open('structured_svm_report.txt', 'w') as f:\n",
    "        f.write(\"# Structured SVM Training Report\\n\\n\")\n",
    "        \n",
    "        f.write(\"## Model Description\\n\")\n",
    "        f.write(\"The model is a BiLSTM-CRF with structured SVM training using a Hamming distance cost function.\\n\")\n",
    "        f.write(f\"- Embedding dimension: {EMBEDDING_DIM}\\n\")\n",
    "        f.write(f\"- Hidden dimension: {HIDDEN_DIM}\\n\")\n",
    "        f.write(f\"- Cost scale: 10.0 (multiplier for Hamming distance)\\n\\n\")\n",
    "        \n",
    "        f.write(\"## Training Details\\n\")\n",
    "        f.write(\"- Implemented early stopping based on F1 score on dev set\\n\")\n",
    "        f.write(\"- Used L2 regularization\\n\")\n",
    "        f.write(\"- Cost-augmented decoding during training\\n\\n\")\n",
    "        \n",
    "        f.write(\"## Parameter Tuning Results\\n\")\n",
    "        f.write(\"| Learning Rate | Reg Strength | Precision | Recall | F1 |\\n\")\n",
    "        f.write(\"|---------------|--------------|-----------|--------|----|\\n\")\n",
    "        \n",
    "        for (lr, reg), result in results.items():\n",
    "            f.write(f\"| {lr} | {reg} | {result['best_precision']:.4f} | {result['best_recall']:.4f} | {result['best_f1']:.4f} |\\n\")\n",
    "        \n",
    "        f.write(f\"\\nBest configuration: lr={best_lr}, reg={best_reg}, F1={best_f1:.4f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"## Final Results\\n\")\n",
    "        f.write(f\"Dev set: Precision={best_f1:.4f}, Recall={results[(best_lr, best_reg)]['best_recall']:.4f}, F1={results[(best_lr, best_reg)]['best_f1']:.4f}\\n\")\n",
    "        f.write(f\"Test set: Precision={test_precision:.4f}, Recall={test_recall:.4f}, F1={test_f1:.4f}\\n\")\n",
    "        \n",
    "    print(\"Done! See structured_svm_report.txt for complete results.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "203A3E1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
