{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CHdbUbDpdTBp"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from conlleval import evaluate as conllevaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "directory = 'results_features/'\n",
    "\n",
    "def decode(input_length, tagset, score, debug=False):\n",
    "    \"\"\"\n",
    "    Compute the highest scoring sequence according to the scoring function.\n",
    "    \"\"\"\n",
    "    viterbi = [[0 for _ in range(input_length)] for _ in range(len(tagset))]\n",
    "    backpointer = [[0 for _ in range(input_length)] for _ in range(len(tagset))]\n",
    "    best_path = []\n",
    "\n",
    "    for i, tag in enumerate(tagset):\n",
    "        viterbi[i][1] = score(tag, \"<START>\", 1)\n",
    "    \n",
    "    if debug: print(viterbi)\n",
    "        \n",
    "    for t in range(2, input_length - 1):\n",
    "        for s, tag in enumerate(tagset):\n",
    "            max_val = 0\n",
    "            max_index = 0\n",
    "            for b, prev_tag in enumerate(tagset):\n",
    "                curr_val = viterbi[b][t - 1] + score(tag, prev_tag, t)\n",
    "                if curr_val > max_val:\n",
    "                    max_val = curr_val\n",
    "                    max_index = b\n",
    "            viterbi[s][t] = max_val\n",
    "            backpointer[s][t] = max_index\n",
    "\n",
    "    for i, tag in enumerate(tagset):\n",
    "        viterbi[i][input_length - 1] = viterbi[i][input_length - 2] + score(\"<STOP>\", tag, input_length - 1)\n",
    "\n",
    "    best_path_prob = 0\n",
    "    index_to_best_path = 0\n",
    "    for i in range(len(tagset)):\n",
    "        if viterbi[i][-1] > best_path_prob:\n",
    "            best_path_prob = viterbi[i][-1]\n",
    "            index_to_best_path = i\n",
    "\n",
    "    best_path = [\"<STOP>\"]\n",
    "    for i in range(input_length - 1, 0, -1):\n",
    "        if i == 1:\n",
    "            best_path.insert(0, \"<START>\")\n",
    "        else:\n",
    "            index_to_best_path = backpointer[index_to_best_path][i]\n",
    "            best_path.insert(0, tagset[index_to_best_path])\n",
    "            if debug: print(best_path)\n",
    "    return best_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(tag_seq, input_length, score):\n",
    "    \"\"\"\n",
    "    Computes the total score of a tag sequence \n",
    "    \"\"\"\n",
    "    total_score = 0\n",
    "    for i in range(1, input_length):\n",
    "        total_score += score(tag_seq[i], tag_seq[i - 1], i)\n",
    "    return total_score\n",
    "\n",
    "\n",
    "def compute_features(tag_seq, input_length, features):\n",
    "    \"\"\"\n",
    "    Compute f(xi, yi)\n",
    "    \"\"\"\n",
    "    feats = FeatureVector({})\n",
    "    for i in range(1, input_length):\n",
    "        feats.times_plus_equal(1, features.compute_features(tag_seq[i], tag_seq[i - 1], i))\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "os.path.exists('ner.train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(training_size, epochs, gradient, parameters, training_observer):\n",
    "    \"\"\"\n",
    "    Stochastic gradient descent\n",
    "    \"\"\"\n",
    "    for i in range(epochs):\n",
    "        print(\"epoch: \", i)\n",
    "        indices = [i for i in range(training_size)]\n",
    "        random.shuffle(indices)\n",
    "        for t in tqdm(indices):\n",
    "            parameters.times_plus_equal(-1, gradient(t))\n",
    "        print(\"Running the training observer\")\n",
    "        training_observer(i, parameters)\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def train(data, feature_names, tagset, epochs):\n",
    "    \"\"\"\n",
    "    Trains the model on the data and returns the parameters\n",
    "    \"\"\"\n",
    "    parameters = FeatureVector({})   \n",
    "\n",
    "    def perceptron_gradient(i):\n",
    "        inputs = data[i]\n",
    "        input_len = len(inputs['tokens'])\n",
    "        gold_labels = inputs['gold_tags']\n",
    "        features = Features(inputs, feature_names)\n",
    "\n",
    "        \n",
    "        def score(cur_tag, pre_tag, i):\n",
    "            return parameters.dot_product(features.compute_features(cur_tag, pre_tag, i))\n",
    "\n",
    "        tags = decode(input_len, tagset, score)\n",
    "\n",
    "        fvector = compute_features(tags, input_len, features)           \n",
    "        fvector.times_plus_equal(-1, compute_features(gold_labels, input_len, features))   \n",
    "        return fvector\n",
    "\n",
    "    def training_observer(epoch, parameters):\n",
    "        \"\"\"\n",
    "        Evaluates the parameters on the development data, and writes out the parameters to a 'model.iter'+epoch and\n",
    "        the predictions to 'ner.dev.out'+epoch.\n",
    "        \"\"\"\n",
    "        dev_data = read_data('ner.dev')[:100]\n",
    "        (_, _, f1) = evaluate(dev_data, parameters, feature_names, tagset)\n",
    "        write_predictions(os.path.join(directory,'ner.dev.out'+str(epoch)), dev_data, parameters, feature_names, tagset)\n",
    "        parameters.write_to_file(os.path.join(directory, 'model.iter'+str(epoch)))\n",
    "        return f1\n",
    "\n",
    "    \n",
    "    return sgd(len(data), epochs, perceptron_gradient, parameters, training_observer)\n",
    "\n",
    "\n",
    "def predict(inputs, input_len, parameters, feature_names, tagset):\n",
    "    features = Features(inputs, feature_names)\n",
    "\n",
    "    def score(cur_tag, pre_tag, i):\n",
    "        return parameters.dot_product(features.compute_features(cur_tag, pre_tag, i))\n",
    "\n",
    "    return decode(input_len, tagset, score)\n",
    "\n",
    "\n",
    "def make_data_point(sent):\n",
    "    dic = {}\n",
    "    sent = [s.strip().split() for s in sent]\n",
    "    dic['tokens'] = ['<START>'] + [s[0] for s in sent] + ['<STOP>']\n",
    "    dic['pos'] = ['<START>'] + [s[1] for s in sent] + ['<STOP>']\n",
    "    dic['NP_chunk'] = ['<START>'] + [s[2] for s in sent] + ['<STOP>']\n",
    "    dic['gold_tags'] = ['<START>'] + [s[3] for s in sent] + ['<STOP>']\n",
    "    return dic\n",
    "\n",
    "def read_data(filename):\n",
    "    data = []\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        sent = []\n",
    "        for line in f.readlines():\n",
    "            if line.strip():\n",
    "                sent.append(line)\n",
    "            else:\n",
    "                data.append(make_data_point(sent))\n",
    "                sent = []\n",
    "        data.append(make_data_point(sent))\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def write_predictions(out_filename, all_inputs, parameters, feature_names, tagset):\n",
    "    with open(out_filename, 'w', encoding='utf-8') as f:\n",
    "        for inputs in all_inputs:\n",
    "            input_len = len(inputs['tokens'])\n",
    "            tag_seq = predict(inputs, input_len, parameters, feature_names, tagset)\n",
    "            for i, tag in enumerate(tag_seq[1:-1]):  \n",
    "                f.write(' '.join([inputs['tokens'][i+1], inputs['pos'][i+1], inputs['NP_chunk'][i+1], inputs['gold_tags'][i+1], tag])+'\\n') # i + 1 because of <START>\n",
    "            f.write('\\n')\n",
    "\n",
    "\n",
    "def evaluate(data, parameters, feature_names, tagset):\n",
    "    all_gold_tags = [ ]\n",
    "    all_predicted_tags = [ ]\n",
    "    for inputs in tqdm(data):\n",
    "        all_gold_tags.extend(inputs['gold_tags'][1:-1])  \n",
    "        input_len = len(inputs['tokens'])\n",
    "        all_predicted_tags.extend(predict(inputs, input_len, parameters, feature_names, tagset)[1:-1]) # deletes <START> and <STOP>\n",
    "    return conllevaluate(all_gold_tags, all_predicted_tags)\n",
    "\n",
    "def test_decoder():\n",
    "    \n",
    "    tagset = ['NN', 'VB']    \n",
    "\n",
    "    def score_wrap(cur_tag, pre_tag, i):\n",
    "        retval = score(cur_tag, pre_tag, i)\n",
    "        print('Score('+cur_tag+','+pre_tag+','+str(i)+') returning '+str(retval))\n",
    "        return retval\n",
    "\n",
    "    def score(cur_tag, pre_tag, i):\n",
    "        if i == 0:\n",
    "            print(\"ERROR: Don't call score for i = 0 (that points to <START>, with nothing before it)\")\n",
    "        if i == 1:\n",
    "            if pre_tag != '<START>':\n",
    "                print(\"ERROR: Previous tag should be <START> for i = 1. Previous tag = \"+pre_tag)\n",
    "            if cur_tag == 'NN':\n",
    "                return 6\n",
    "            if cur_tag == 'VB':\n",
    "                return 4\n",
    "        if i == 2:\n",
    "            if cur_tag == 'NN' and pre_tag == 'NN':\n",
    "                return 4\n",
    "            if cur_tag == 'NN' and pre_tag == 'VB':\n",
    "                return 9\n",
    "            if cur_tag == 'VB' and pre_tag == 'NN':\n",
    "                return 5\n",
    "            if cur_tag == 'VB' and pre_tag == 'VB':\n",
    "                return 0\n",
    "        if i == 3:\n",
    "            if cur_tag != '<STOP>':\n",
    "                print('ERROR: Current tag at i = 3 should be <STOP>. Current tag = '+cur_tag)\n",
    "            if pre_tag == 'NN':\n",
    "                return 1\n",
    "            if pre_tag == 'VB':\n",
    "                return 1\n",
    "\n",
    "    predicted_tag_seq = decode(4, tagset, score_wrap)\n",
    "    print('Predicted tag sequence should be = <START> VB NN <STOP>')\n",
    "    print('Predicted tag sequence = '+' '.join(predicted_tag_seq))\n",
    "    print(\"Score of ['<START>','VB','NN','<STOP>'] = \"+str(compute_score(['<START>','VB','NN','<STOP>'], 4, score)))\n",
    "    print('Max score should be = 14')\n",
    "    print('Max score = '+str(compute_score(predicted_tag_seq, 4, score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_predict(data_filename, model_filename, use_four_features=False):\n",
    "    data = read_data(data_filename)\n",
    "    parameters = FeatureVector({})\n",
    "    parameters.read_from_file(model_filename)\n",
    "\n",
    "    tagset = ['B-PER', 'B-LOC', 'B-ORG', 'B-MISC', 'I-PER', 'I-LOC', 'I-ORG', 'I-MISC', 'O']\n",
    "\n",
    "    feature_names = ['tag', 'prev_tag', 'current_word', 'curr_pos_tag', 'shape_curr_word', 'len_k', 'in_gazetteer', 'start_cap']\n",
    "\n",
    "    write_predictions(data_filename+'.out', data, parameters, feature_names, tagset)\n",
    "    evaluate(data, parameters, feature_names, tagset)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def main_train():\n",
    "    print('Reading training data')\n",
    "    train_data = read_data('ner.train')[:1100]\n",
    "    tagset = ['B-PER', 'B-LOC', 'B-ORG', 'B-MISC', 'I-PER', 'I-LOC', 'I-ORG', 'I-MISC', 'O']\n",
    "    feature_names = ['tag', 'prev_tag', 'current_word', 'curr_pos_tag', 'shape_curr_word', 'len_k', 'in_gazetteer', 'start_cap']\n",
    "    \n",
    "    print('Training...')\n",
    "    parameters = train(train_data, feature_names, tagset, epochs=10)\n",
    "    print('Training done')\n",
    "    dev_data = read_data('ner.dev')[:1100]\n",
    "    evaluate(dev_data, parameters, feature_names, tagset)\n",
    "    test_data = read_data('ner.test')[:1100]\n",
    "    \n",
    "    evaluate(test_data, parameters, feature_names, tagset)\n",
    "    parameters.write_to_file('model')\n",
    "\n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Features(object):\n",
    "    def __init__(self, inputs, feature_names):\n",
    "        self.feature_names = feature_names\n",
    "        self.inputs = inputs\n",
    "        self.gazette_dict = {}\n",
    "\n",
    "        with open('gazetteer.txt', 'r') as file:\n",
    "            for row in file:\n",
    "                words = row.split(' ')\n",
    "                value = words[0]\n",
    "                for w in words[1:]:\n",
    "                    if (w in self.gazette_dict.keys()):\n",
    "                        self.gazette_dict[w].append(value)\n",
    "                    else:\n",
    "                        self.gazette_dict[w] = [value]\n",
    "\n",
    "    def compute_features(self, cur_tag, pre_tag, i):\n",
    "\n",
    "        feats = FeatureVector({})\n",
    "        curr_word = self.inputs['tokens'][i]\n",
    "        len_curr_word = len(self.inputs['tokens'][i])\n",
    "        \n",
    "        if 'tag' in self.feature_names:\n",
    "            feats.times_plus_equal(1, FeatureVector({'t='+cur_tag: 1}))\n",
    "        if 'prev_tag' in self.feature_names:\n",
    "            feats.times_plus_equal(1, FeatureVector({'ti='+cur_tag+\"+ti-1=\"+pre_tag: 1}))\n",
    "        if 'current_word' in self.feature_names:\n",
    "            feats.times_plus_equal(1, FeatureVector({'t='+cur_tag+'+w='+self.inputs['tokens'][i]: 1}))\n",
    "        if 'curr_pos_tag' in self.feature_names:\n",
    "            feats.times_plus_equal(1, FeatureVector({'t='+cur_tag+'+pi='+self.inputs['pos'][i]: 1}))\n",
    "        \n",
    "        if 'shape_curr_word' in self.feature_names:\n",
    "            word_shape = ''.join(['a' if c.isalpha() else 'A' if c.isupper() else 'd' for c in curr_word])\n",
    "            feats.times_plus_equal(1, FeatureVector({'t='+cur_tag+'si'+word_shape: 1}))\n",
    "\n",
    "\n",
    "        if 'len_k' in self.feature_names:\n",
    "            for j in range(1, min(5, len(curr_word) + 1)): \n",
    "                feats.times_plus_equal(1, FeatureVector({'t='+cur_tag+'+PRE'+str(j)+'='+curr_word[:j]: 1}))\n",
    "\n",
    "\n",
    "       \n",
    "        if 'in_gazetteer' in self.feature_names:\n",
    "            if (curr_word) in self.gazette_dict.keys():\n",
    "                if self.gazette_dict[curr_word] == cur_tag:\n",
    "                    feats.times_plus_equal(1, FeatureVector({'t='+cur_tag+'+GAZ='+'True': 1}))\n",
    "            \n",
    "\n",
    "        if 'start_cap' in self.feature_names:\n",
    "            if(curr_word[0].isupper()):\n",
    "                feats.times_plus_equal(1, FeatureVector({'t='+cur_tag+'+CAP='+'True': 1}))\n",
    "        \n",
    "        return feats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training data\n",
      "Training...\n",
      "epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [00:52<00:00, 20.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the training observer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 20.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 1314 tokens with 189 phrases; found: 313 phrases; correct: 67.\n",
      "accuracy:  40.38%; (non-O)\n",
      "accuracy:  77.32%; precision:  21.41%; recall:  35.45%; FB1:  26.69\n",
      "              LOC: precision:  17.80%; recall:  39.62%; FB1:  24.56  118\n",
      "             MISC: precision:  15.38%; recall:  18.18%; FB1:  16.67  13\n",
      "              ORG: precision:  50.00%; recall:  22.86%; FB1:  31.37  32\n",
      "              PER: precision:  18.67%; recall:  50.91%; FB1:  27.32  150\n",
      "Writing to results_features/model.iter0\n",
      "epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [00:53<00:00, 20.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the training observer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 20.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 1314 tokens with 189 phrases; found: 276 phrases; correct: 53.\n",
      "accuracy:  31.92%; (non-O)\n",
      "accuracy:  77.02%; precision:  19.20%; recall:  28.04%; FB1:  22.80\n",
      "              LOC: precision:  20.22%; recall:  33.96%; FB1:  25.35  89\n",
      "             MISC: precision:  33.33%; recall:  18.18%; FB1:  23.53  6\n",
      "              ORG: precision:  37.84%; recall:  20.00%; FB1:  26.17  37\n",
      "              PER: precision:  13.19%; recall:  34.55%; FB1:  19.10  144\n",
      "Writing to results_features/model.iter1\n",
      "epoch:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [00:53<00:00, 20.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the training observer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 20.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 1314 tokens with 189 phrases; found: 277 phrases; correct: 42.\n",
      "accuracy:  26.54%; (non-O)\n",
      "accuracy:  75.65%; precision:  15.16%; recall:  22.22%; FB1:  18.03\n",
      "              LOC: precision:  18.52%; recall:  37.74%; FB1:  24.84  108\n",
      "             MISC: precision:  16.67%; recall:  27.27%; FB1:  20.69  18\n",
      "              ORG: precision:  15.38%; recall:   2.86%; FB1:   4.82  13\n",
      "              PER: precision:  12.32%; recall:  30.91%; FB1:  17.62  138\n",
      "Writing to results_features/model.iter2\n",
      "epoch:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [00:53<00:00, 20.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the training observer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 19.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 1314 tokens with 189 phrases; found: 298 phrases; correct: 78.\n",
      "accuracy:  48.08%; (non-O)\n",
      "accuracy:  78.77%; precision:  26.17%; recall:  41.27%; FB1:  32.03\n",
      "              LOC: precision:  29.03%; recall:  33.96%; FB1:  31.30  62\n",
      "             MISC: precision:  28.57%; recall:  36.36%; FB1:  32.00  14\n",
      "              ORG: precision:  36.21%; recall:  30.00%; FB1:  32.81  58\n",
      "              PER: precision:  21.34%; recall:  63.64%; FB1:  31.96  164\n",
      "Writing to results_features/model.iter3\n",
      "epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [00:53<00:00, 20.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the training observer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 18.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 1314 tokens with 189 phrases; found: 271 phrases; correct: 77.\n",
      "accuracy:  44.23%; (non-O)\n",
      "accuracy:  79.83%; precision:  28.41%; recall:  40.74%; FB1:  33.48\n",
      "              LOC: precision:  34.88%; recall:  28.30%; FB1:  31.25  43\n",
      "             MISC: precision:  15.00%; recall:  27.27%; FB1:  19.35  20\n",
      "              ORG: precision:  54.39%; recall:  44.29%; FB1:  48.82  57\n",
      "              PER: precision:  18.54%; recall:  50.91%; FB1:  27.18  151\n",
      "Writing to results_features/model.iter4\n",
      "epoch:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [00:53<00:00, 20.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the training observer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 20.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 1314 tokens with 189 phrases; found: 278 phrases; correct: 56.\n",
      "accuracy:  36.15%; (non-O)\n",
      "accuracy:  77.09%; precision:  20.14%; recall:  29.63%; FB1:  23.98\n",
      "              LOC: precision:  25.71%; recall:  33.96%; FB1:  29.27  70\n",
      "             MISC: precision:  13.33%; recall:  18.18%; FB1:  15.38  15\n",
      "              ORG: precision:  21.05%; recall:  11.43%; FB1:  14.81  38\n",
      "              PER: precision:  18.06%; recall:  50.91%; FB1:  26.67  155\n",
      "Writing to results_features/model.iter5\n",
      "epoch:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [00:53<00:00, 20.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the training observer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 20.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 1314 tokens with 189 phrases; found: 285 phrases; correct: 63.\n",
      "accuracy:  35.77%; (non-O)\n",
      "accuracy:  76.64%; precision:  22.11%; recall:  33.33%; FB1:  26.58\n",
      "              LOC: precision:  29.03%; recall:  33.96%; FB1:  31.30  62\n",
      "             MISC: precision:  21.43%; recall:  27.27%; FB1:  24.00  14\n",
      "              ORG: precision:  33.85%; recall:  31.43%; FB1:  32.59  65\n",
      "              PER: precision:  13.89%; recall:  36.36%; FB1:  20.10  144\n",
      "Writing to results_features/model.iter6\n",
      "epoch:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [00:53<00:00, 20.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the training observer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 20.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 1314 tokens with 189 phrases; found: 287 phrases; correct: 60.\n",
      "accuracy:  39.23%; (non-O)\n",
      "accuracy:  77.17%; precision:  20.91%; recall:  31.75%; FB1:  25.21\n",
      "              LOC: precision:  19.15%; recall:  33.96%; FB1:  24.49  94\n",
      "             MISC: precision:  40.00%; recall:  18.18%; FB1:  25.00  5\n",
      "              ORG: precision:  38.10%; recall:  11.43%; FB1:  17.58  21\n",
      "              PER: precision:  19.16%; recall:  58.18%; FB1:  28.83  167\n",
      "Writing to results_features/model.iter7\n",
      "epoch:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [00:53<00:00, 20.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the training observer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 20.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 1314 tokens with 189 phrases; found: 272 phrases; correct: 55.\n",
      "accuracy:  31.15%; (non-O)\n",
      "accuracy:  76.03%; precision:  20.22%; recall:  29.10%; FB1:  23.86\n",
      "              LOC: precision:  26.98%; recall:  32.08%; FB1:  29.31  63\n",
      "             MISC: precision:  33.33%; recall:   9.09%; FB1:  14.29  3\n",
      "              ORG: precision:  33.93%; recall:  27.14%; FB1:  30.16  56\n",
      "              PER: precision:  12.00%; recall:  32.73%; FB1:  17.56  150\n",
      "Writing to results_features/model.iter8\n",
      "epoch:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [00:53<00:00, 20.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the training observer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 20.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 1314 tokens with 189 phrases; found: 295 phrases; correct: 72.\n",
      "accuracy:  41.15%; (non-O)\n",
      "accuracy:  77.47%; precision:  24.41%; recall:  38.10%; FB1:  29.75\n",
      "              LOC: precision:  31.67%; recall:  35.85%; FB1:  33.63  60\n",
      "             MISC: precision:  22.22%; recall:  18.18%; FB1:  20.00  9\n",
      "              ORG: precision:  36.00%; recall:  38.57%; FB1:  37.24  75\n",
      "              PER: precision:  15.89%; recall:  43.64%; FB1:  23.30  151\n",
      "Writing to results_features/model.iter9\n",
      "Training done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [00:54<00:00, 20.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 15257 tokens with 1808 phrases; found: 2903 phrases; correct: 722.\n",
      "accuracy:  44.52%; (non-O)\n",
      "accuracy:  81.39%; precision:  24.87%; recall:  39.93%; FB1:  30.65\n",
      "              LOC: precision:  50.30%; recall:  57.02%; FB1:  53.45  662\n",
      "             MISC: precision:  33.33%; recall:  11.06%; FB1:  16.60  66\n",
      "              ORG: precision:  23.64%; recall:  32.41%; FB1:  27.34  495\n",
      "              PER: precision:  14.88%; recall:  37.65%; FB1:  21.33  1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [00:53<00:00, 20.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 13063 tokens with 1888 phrases; found: 3058 phrases; correct: 799.\n",
      "accuracy:  49.04%; (non-O)\n",
      "accuracy:  77.64%; precision:  26.13%; recall:  42.32%; FB1:  32.31\n",
      "              LOC: precision:  47.01%; recall:  56.57%; FB1:  51.35  568\n",
      "             MISC: precision:  38.17%; recall:  24.39%; FB1:  29.76  131\n",
      "              ORG: precision:  38.45%; recall:  34.62%; FB1:  36.43  489\n",
      "              PER: precision:  15.72%; recall:  44.01%; FB1:  23.17  1870\n",
      "Writing to model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3466/3466 [02:54<00:00, 19.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 51578 tokens with 5917 phrases; found: 9216 phrases; correct: 2486.\n",
      "accuracy:  46.20%; (non-O)\n",
      "accuracy:  82.53%; precision:  26.97%; recall:  42.01%; FB1:  32.86\n",
      "              LOC: precision:  52.03%; recall:  54.04%; FB1:  53.02  1901\n",
      "             MISC: precision:  47.08%; recall:  25.60%; FB1:  33.17  497\n",
      "              ORG: precision:  31.95%; recall:  35.72%; FB1:  33.73  1499\n",
      "              PER: precision:  14.74%; recall:  42.79%; FB1:  21.93  5319\n"
     ]
    }
   ],
   "source": [
    "class FeatureVector(object):\n",
    "\n",
    "    def __init__(self, fdict):\n",
    "        self.fdict = fdict\n",
    "\n",
    "    def times_plus_equal(self, scalar, v2):\n",
    "        \n",
    "        try: \n",
    "            for key, value in v2.fdict.items():\n",
    "                self.fdict[key] = scalar * value + self.fdict.get(key, 0)\n",
    "        except:\n",
    "            print(v2)\n",
    "\n",
    "    def dot_product(self, v2):\n",
    "        retval = 0\n",
    "        for key, value in v2.fdict.items():\n",
    "            retval += value * self.fdict.get(key, 0)\n",
    "        return retval\n",
    "\n",
    "    def write_to_file(self, filename):\n",
    "        print('Writing to ' + filename)\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            for key, value in self.fdict.items():\n",
    "                f.write('{} {}\\n'.format(key, value))\n",
    "\n",
    "\n",
    "    def read_from_file(self, filename):\n",
    "        self.fdict = {}\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                txt = line.split()\n",
    "                self.fdict[txt[0]] = float(txt[1])\n",
    "\n",
    "main_train()   \n",
    "main_predict('ner.dev', 'model')  # Uncomment to predict on 'dev.ner' using the model 'model' (need to implement 'decode' function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score(NN,<START>,1) returning 6\n",
      "Score(VB,<START>,1) returning 4\n",
      "Score(NN,NN,2) returning 4\n",
      "Score(NN,VB,2) returning 9\n",
      "Score(VB,NN,2) returning 5\n",
      "Score(VB,VB,2) returning 0\n",
      "Score(<STOP>,NN,3) returning 1\n",
      "Score(<STOP>,VB,3) returning 1\n",
      "Predicted tag sequence should be = <START> VB NN <STOP>\n",
      "Predicted tag sequence = <START> VB NN <STOP>\n",
      "Score of ['<START>','VB','NN','<STOP>'] = 14\n",
      "Max score should be = 14\n",
      "Max score = 14\n"
     ]
    }
   ],
   "source": [
    "test_decoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training using SGD (trained on 1100 training examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 3466/3466 [04:18<00:00, 13.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 51578 tokens with 5917 phrases; found: 7975 phrases; correct: 1949.\n",
      "accuracy:  36.78%; (non-O)\n",
      "accuracy:  81.79%; precision:  24.44%; recall:  32.94%; FB1:  28.06\n",
      "              LOC: precision:  55.78%; recall:  46.17%; FB1:  50.52  1515\n",
      "             MISC: precision:  30.63%; recall:  20.68%; FB1:  24.69  617\n",
      "              ORG: precision:  37.97%; recall:  18.12%; FB1:  24.53  640\n",
      "              PER: precision:  12.92%; recall:  36.68%; FB1:  19.10  5203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main_predict('ner.dev', 'results_features/model.iter9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 3684/3684 [04:46<00:00, 12.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 46666 tokens with 5616 phrases; found: 8312 phrases; correct: 1757.\n",
      "accuracy:  35.85%; (non-O)\n",
      "accuracy:  79.24%; precision:  21.14%; recall:  31.29%; FB1:  25.23\n",
      "              LOC: precision:  53.43%; recall:  46.34%; FB1:  49.63  1445\n",
      "             MISC: precision:  19.22%; recall:  15.55%; FB1:  17.19  567\n",
      "              ORG: precision:  35.65%; recall:  15.24%; FB1:  21.35  704\n",
      "              PER: precision:  11.17%; recall:  39.01%; FB1:  17.37  5596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main_predict('ner.test', 'results_features/model.iter9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['<START>', 'SOCCER', '-', 'JAPAN', 'GET', 'LUCKY', 'WIN', ',', 'CHINA', 'IN', 'SURPRISE', 'DEFEAT', '.', '<STOP>'], 'pos': ['<START>', 'NN', ':', 'NNP', 'VB', 'NNP', 'NNP', ',', 'NNP', 'IN', 'DT', 'NN', '.', '<STOP>'], 'NP_chunk': ['<START>', 'I-NP', 'O', 'I-NP', 'I-VP', 'I-NP', 'I-NP', 'O', 'I-NP', 'I-PP', 'I-NP', 'I-NP', 'O', '<STOP>'], 'gold_tags': ['<START>', 'O', 'O', 'I-LOC', 'O', 'O', 'O', 'O', 'I-PER', 'O', 'O', 'O', 'O', '<STOP>']}\n"
     ]
    }
   ],
   "source": [
    "data = read_data('ner.test')[:4]\n",
    "parameters = FeatureVector({})\n",
    "parameters.read_from_file('results_features/model.iter9')\n",
    "\n",
    "tagset = ['B-PER', 'B-LOC', 'B-ORG', 'B-MISC', 'I-PER', 'I-LOC', 'I-ORG', 'I-MISC', 'O']\n",
    "\n",
    "feature_names = ['tag', 'prev_tag', 'current_word', 'curr_pos_tag', 'shape_curr_word', 'len_k', 'in_gazetteer', 'start_cap']\n",
    "\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 10.08it/s]\n"
     ]
    }
   ],
   "source": [
    "all_gold_tags = [ ]\n",
    "all_predicted_tags = [ ]\n",
    "for inputs in tqdm(data):\n",
    "    all_gold_tags.append(inputs['gold_tags'][1:-1])  # deletes <START> and <STOP>\n",
    "    input_len = len(inputs['tokens'])\n",
    "    all_predicted_tags.append(predict(inputs, input_len, parameters, feature_names, tagset)[1:-1]) # deletes <START> and <STOP>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_id = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<START>', 'Japan', 'began', 'the', 'defence', 'of', 'their', 'Asian', 'Cup', 'title', 'with', 'a', 'lucky', '2-1', 'win', 'against', 'Syria', 'in', 'a', 'Group', 'C', 'championship', 'match', 'on', 'Friday', '.', '<STOP>']\n"
     ]
    }
   ],
   "source": [
    "print(data[display_id]['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-LOC', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(all_gold_tags[display_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-LOC', 'O', 'O', 'I-ORG', 'O', 'O', 'O', 'O', 'I-MISC', 'B-PER']\n"
     ]
    }
   ],
   "source": [
    "print(all_predicted_tags[display_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gHEtAu_LfmPG"
   },
   "outputs": [],
   "source": [
    "!cat \"results_features/model.iter9\" | awk '{print $2, $1}' | sort -gr > \"results_features/model.sorted.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bS4d4Acfp1S"
   },
   "source": [
    "The file `model.sorted.txt` will be viewable in your Google Drive folder."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP-202_A1_Code.ipynb",
   "provenance": [
    {
     "file_id": "186hCS3cdEtl0vpkgCXHYgLUu-BkFZZ9T",
     "timestamp": 1583157228957
    }
   ]
  },
  "kernelspec": {
   "display_name": "203A3E1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
